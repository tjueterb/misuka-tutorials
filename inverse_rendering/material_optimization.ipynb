{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Material optimization\n",
    "\n",
    "In this notebook we calibrate the spectrally varying absorption and scattering coefficient of a wall in order to match the simulated ETC to a simulated target ETC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Misuka can be used to solve inverse problems using a technique known as *differentiable rendering*. It interprets the rendering algorithm as a function $f(\\mathbf{\\pi})$ that converts an input $\\mathbf{\\pi}$ (the scene description) into an output $H(t)$, the Energy Time Curve (ETC). This function $f$ is then mathematically differentiated to obtain $\\frac{\\partial H}{\\partial \\mathbf{\\pi}}$, providing a first-order approximation of how a desired change in the output $H(t)$ (the rendering) can be achieved by changing the inputs $\\mathbf{\\pi}$ (the scene description). Together with a differentiable *objective function* $\\mathcal{L}(H)$ that quantifies the suitability of tentative scene parameters, a gradient-based optimization algorithm such as stochastic gradient descent or Adam can then be used to find a sequence of scene parameters $\\mathbf{\\pi}_0$, $\\mathbf{\\pi}_1$, $\\mathbf{\\pi}_2$, etc., that successively improve the objective function.\n",
    "\n",
    "<div align=\"center\"><img src=\"../../resources/data_acoustic/docs/images/autodiff/autodiff_figure.jpg\" width=\"60%\"/></div>\n",
    "\n",
    "In this tutorial, we will build a simple example application that showcases differentiation and optimization through an acoustic simulation:\n",
    "\n",
    "1. We will first render a reference ETC of a simple scene with just one reflecting surface.\n",
    "2. Then, we will change the absorption and scattering coefficient of the surface.\n",
    "3. Finally, we will try to recover the original absorption and scattering coefficients of the surface using differentiation along with the reference ETC generated in step 1.\n",
    "\n",
    "<div class=\"admonition important alert alert-block alert-success\">\n",
    "\n",
    "ðŸš€ **You will learn how to:**\n",
    "    \n",
    "<ul>\n",
    "  <li>Build a simple scene with python only</li>\n",
    "  <li>Update a surface's absorption and scattering coefficient with a function</li>\n",
    "  <li>Build an optimization loop using the <code>Optimizer</code> classes</li>\n",
    "  <li>Perform a gradient-based optimization using automatic differentiation</li>\n",
    "</ul>\n",
    "    \n",
    "</div>\n",
    "\n",
    "    \n",
    "[1]: https://drjit.readthedocs.io/en/master/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "In order to use the automatic differentiation, we need to enable a variant that supports it. Those are the ones containing `_ad` after the backend description. E.g. `cuda_ad_acoustic`, `llvm_ad_acoustic`, â€¦\n",
    "\n",
    "<div class=\"admonition important alert alert-block alert-info\">\n",
    "    \n",
    "If you receive an error mentioning that the requested variant is not supported, add the desired variant to your `build/mitsuba.conf` file and recompile the project ([documentation][1]).\n",
    "\n",
    "[1]: https://mitsuba.readthedocs.io/en/latest/src/developer_guide/compiling.html#configuring-mitsuba-conf\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import drjit as dr\n",
    "import mitsuba as mi\n",
    "mi.set_variant('cuda_ad_acoustic', 'llvm_ad_acoustic')\n",
    "from mitsuba import ScalarTransform4f as tf # needed to move and scale geometry\n",
    "\n",
    "# Fixed rng seeds for reproducibility\n",
    "seed   = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene Construction\n",
    "\n",
    "First, we set up the scene geometry using Mitsuba's basic rectangle shape. We place the reflector in the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_pos    = np.array([ 0, 0, 0])\n",
    "mic_pos     = np.array([ 5, 0, 5])\n",
    "speaker_pos = np.array([-5, 0, 5])\n",
    "\n",
    "scene_dict = {\n",
    "    'type': 'scene',\n",
    "\n",
    "    'speaker': {\n",
    "        'type': 'sphere',\n",
    "        'center': speaker_pos,\n",
    "        'radius': 2,\n",
    "        'emitter': {\n",
    "            'type': 'area',\n",
    "            'radiance': {\n",
    "                'type': 'uniform',\n",
    "                'value': 100.,\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "\n",
    "    'reflector': {\n",
    "        'type': 'rectangle',\n",
    "        'to_world': tf().scale(20).translate(wall_pos), # Transformations are applied from right to left\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will use Mitsuba's BlendBSDF to model a specular + diffuse reflection BSDF that is commonly used in acoustics. A few details require special attention:\n",
    "\n",
    "- In acoustics, the absorption coefficient $\\alpha$ expresses the fraction of energy absorbed by a material. Mitsuba's BSDFs use the reflectance $R$, which expresses the of reflected energy. The two are related by $R = 1 - \\alpha$.\n",
    "- The BlendBSDF combines the specular and diffuse contributions using its weight parameter. Since it does not support spectrally varying weights, we use a constant value here. An acoustic BSDF with support for spectrally varying scattering coefficients will be added to misuka in the near future.\n",
    "- In order to correctly propagate gradients through the BSDF, we use the differentiable `roughconductor` BSDF (left image). However, we use a very low roughness (`alpha`) value so we effectively converge to a specular reflection (right image).\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"../../resources/data_acoustic/docs/images/bsdf/acoustic_bsdf_rough.jpg\" width=\"30%\"/>\n",
    "<img src=\"../../resources/data_acoustic/docs/images/bsdf/acoustic_bsdf.jpg\" width=\"30%\"/>\n",
    "</div>\n",
    "\n",
    "Spectrally varying parameters (like the reflectance) can be imported as a list of frequency-value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absorption_target  = [(125, 0.1), (250, 0.4), (500, 0.7), (1000, 0.9)]\n",
    "reflectance_target = [(i, 1 - j) for i, j in absorption_target]\n",
    "frequencies        = [i[0] for i in absorption_target] # we will use this later for plot legends\n",
    "scattering_target  = 0.1\n",
    "\n",
    "# Add the BSDF to the scene dictionary\n",
    "scene_dict['reflector']['bsdf'] = {\n",
    "    'type': 'blendbsdf',\n",
    "    'weight': scattering_target,\n",
    "    'bsdf_0': {\n",
    "        'type': 'roughconductor',\n",
    "        'alpha': 0.01,\n",
    "        'specular_reflectance': {\n",
    "            'type': 'spectrum',\n",
    "            'value': reflectance_target,\n",
    "        },\n",
    "    },\n",
    "    'bsdf_1': {\n",
    "        'type': 'diffuse',\n",
    "        'reflectance': {\n",
    "            'type': 'spectrum',\n",
    "            'value': reflectance_target,\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load the scene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = mi.load_dict(scene_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensor and Integrator\n",
    "\n",
    "Now that the scene geometry is complete, we need to define the sensor and integrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = 0.1\n",
    "sampling_rate = 5000\n",
    "t_bins = int(max_time * sampling_rate)\n",
    "\n",
    "microphone = mi.load_dict({\n",
    "    'type': 'microphone',\n",
    "    'to_world': tf().translate(mic_pos),\n",
    "    'film': {\n",
    "        'type': 'tape',\n",
    "        'frequencies':  '125, 250, 500, 1000',  # Frequencies that we want to render\n",
    "        'time_bins': t_bins,                    # Number of time bins to use\n",
    "        'rfilter':   {'type': 'box'},           # no smoothing in the time domain\n",
    "    },\n",
    "})\n",
    "\n",
    "integrator_acoustic = mi.load_dict({\n",
    "    'type': 'acoustic_prb',          # Acoustic Path Replay Backpropagation\n",
    "    'max_depth': 2,                  # Stopping criterion for the max reflection depth, 1 = direct sound, 2 = 1st order\n",
    "    'max_time': max_time,            # Stopping criterion for the maximum propagation time\n",
    "    'track_time_derivatives': False, # In a static scene we do not need to track time derivatives\n",
    "    'skip_direct': False,            # We can skip the direct sound if we want to\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Energy Time Curve\n",
    "\n",
    "We render a reference ETC of the original scene that will later be used in the objective function for the optimization. \n",
    "Ideally, this reference ETC should contain very little noise as it will hinder the optimization process otherwise. \n",
    "For best results, we should to render it with with as many samples as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spp_ref = 2**26\n",
    "etc_ref = mi.render(scene,sensor=microphone, integrator=integrator_acoustic, spp=spp_ref) / spp_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_etc(etc: mi.TensorXf, sampling_rate: int, max_time: float,\n",
    "             dB: bool = True, normalize: bool = False,\n",
    "             bottom: float = -100, ax=None, **kwargs):\n",
    "    \"\"\"Plot Energy Time Curve\"\"\"\n",
    "    times = np.arange(max_time, step=1/sampling_rate)\n",
    "    etc = etc.numpy().squeeze()\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    ax.set_xlabel('Time in s')\n",
    "    ax.set_ylabel('Amplitude')\n",
    "\n",
    "    if normalize:\n",
    "        etc  /= np.max(etc)\n",
    "\n",
    "    if dB:\n",
    "        with np.errstate(divide='ignore'):\n",
    "            etc = 20 * np.nan_to_num(np.log10(np.abs(etc)), neginf=-300)\n",
    "        ax.set_ylabel('Amplitude in dB')\n",
    "\n",
    "    ax.plot(times, etc, **kwargs)\n",
    "    ax.set_xlim(0, max_time)\n",
    "    ax.set_ylim(bottom=bottom, top=np.max(etc) + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_etc(etc_ref, sampling_rate, max_time, dB=True, normalize=False, bottom=-100, label=frequencies)\n",
    "plt.legend(title = 'Frequency in Hz')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial State\n",
    "\n",
    "In order to optimize the material properties, we set up an Adam optimizer and define the initial values. The number of absorption values must match the number of frequency nodes we defined in the spectral values above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = mi.ad.Adam(lr=0.005)\n",
    "opt['absorption'] = mi.Float([0.5, 0.5, 0.5, 0.5])\n",
    "opt['scattering'] = mi.Float(0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `traverse` mechanism, we can pick the parameters that we will be optimizing and change its value away from the correct value. The goal of the optimization process will be to recover the original value of this parameter using gradient descent.\n",
    "\n",
    "Because we need to update both the scattering coeffiecient (`weight`) and the reflectance of the specular and diffuse part of the BSDF (`bsdf_0.specular_reflectance`, `bsdf_1.reflectance`), it is convenient to write a small function that updates all values at once\n",
    "\n",
    "The `update_material_properties()` function ensures that:\n",
    "1. All coefficients remain within physical bounds $[0, 1]$\n",
    "2. The reflectance values are updated as `1 - absorption` for both specular and diffuse components\n",
    "3. The scattering weight controls the blend between specular and diffuse reflection\n",
    "4. Changes are applied to the scene parameters through `params.update()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = mi.traverse(scene)\n",
    "\n",
    "def update_material_properties(params: mi.SceneParameters, opt: mi.ad.Optimizer):\n",
    "    \"\"\"Write absorption and scattering coefficient to the scene parameters\"\"\"\n",
    "\n",
    "    # clip values to [0, 1]\n",
    "    opt['absorption'] = dr.clip(opt['absorption'], 0.0, 1.0)\n",
    "    opt['scattering'] = dr.clip(opt['scattering'], 0.0, 1.0)\n",
    "\n",
    "    # update the parameter dictionary\n",
    "    params['reflector.bsdf.bsdf_0.specular_reflectance.values'] = 1-opt['absorption']\n",
    "    params['reflector.bsdf.bsdf_1.reflectance.values']          = 1-opt['absorption']\n",
    "    params['reflector.bsdf.weight.value']                       = opt['scattering']\n",
    "\n",
    "    params.update(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After updating we can render the scene again and see that the initial condition has been applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_material_properties(params, opt)\n",
    "etc_initial = mi.render(scene, integrator=integrator_acoustic, sensor=microphone, spp=spp_ref) / spp_ref\n",
    "plot_etc(etc_initial, sampling_rate, max_time, dB=True, normalize=False, bottom=-100, label=frequencies)\n",
    "plt.legend(title = 'Frequency in Hz')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "At every iteration of the gradient descent, we will compute the derivatives of the scene parameters with respect to the objective function. In this simple experiment, we use the total squared error between the current ETC and the reference created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(etc):\n",
    "    return dr.mean(dr.square(etc - etc_ref))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell we define the hyper parameters controlling our optimization loop, such as the the number of samples and number of iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spp_opt = 2**18\n",
    "iteration_count = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IGNORE THIS: When running under pytest, adjust parameters to reduce computation time\n",
    "import os\n",
    "if 'PYTEST_CURRENT_TEST' in os.environ:\n",
    "    iteration_count = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Loop\n",
    "It is now time to actually perform the gradient-descent loop.\n",
    "\n",
    "We first set up empty arrays to store the optimization progress and a self-updating plot. The dashed lines show the target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absorption_values         = np.empty((iteration_count, len(absorption_target)))\n",
    "scattering_values, losses = np.empty(iteration_count), np.empty(iteration_count)\n",
    "\n",
    "%matplotlib widget\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(10, 3), width_ratios=[1,1,1,1.5], layout='constrained')\n",
    "ax1.set_xlim(-iteration_count * 0.02, iteration_count * 1.02)\n",
    "ax2.set_xlim(-iteration_count * 0.02, iteration_count * 1.02)\n",
    "ax3.set_xlim(-iteration_count * 0.02, iteration_count * 1.02)\n",
    "\n",
    "for f in range(len(absorption_target)):\n",
    "    ax1.axhline(absorption_target[f][1], linestyle='dotted', color=f'C{f}')\n",
    "ax2.axhline(scattering_target, linestyle='dotted')\n",
    "\n",
    "ax1.set_ylim(-0.1, 1.1)\n",
    "ax2.set_ylim(-0.1, 1.1)\n",
    "ax3.set_ylim(-0.1, 1.1)\n",
    "\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax2.set_xlabel('Iteration')\n",
    "ax3.set_xlabel('Iteration')\n",
    "ax4.set_xlabel('Time in s')\n",
    "ax1.set_ylabel(rf'Absorption coefficient')\n",
    "ax2.set_ylabel(rf'Scattering coefficient')\n",
    "ax3.set_ylabel('Loss')\n",
    "ax4.set_ylabel('ETC in dB')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now time to run the optimization loop.\n",
    "\n",
    "In order to keep the (noisy) simulations statistically independent and to prevent overfitting we use a new rng seed for each iteration. This produces different noise patterns in each iteration.\n",
    "At some point the gradients become smaller than the noise, indicating that our optimization has converged. If we want to improve the quality of the optimization we need to increase the number of samples per iteration `spp_opt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(iteration_count):\n",
    "    # Perform a (noisy) differentiable rendering of the scene. Use a different rng seed for each iteration\n",
    "    etc = mi.render(scene, params, integrator=integrator_acoustic, sensor=microphone,\n",
    "                    spp=spp_opt, seed=seed+i) / spp_opt\n",
    "\n",
    "    # Evaluate the objective function\n",
    "    loss = mse(etc)\n",
    "\n",
    "    # Store the current absorption and scattering values\n",
    "    absorption_values[i] = opt['absorption']\n",
    "    scattering_values[i] = opt['scattering'][0]\n",
    "    losses[i] = loss.numpy()\n",
    "\n",
    "    # Backpropagate the loss through the rendering process\n",
    "    dr.backward(loss)\n",
    "\n",
    "    # Take a gradient descent step\n",
    "    opt.step()\n",
    "\n",
    "    # Update the scene\n",
    "    update_material_properties(params, opt)\n",
    "\n",
    "    # Update the plot\n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "    ax3.clear()\n",
    "    ax4.clear()\n",
    "\n",
    "    ax1.plot(absorption_values[:i])\n",
    "    for f in range(len(absorption_target)):\n",
    "        ax1.axhline(absorption_target[f][1], linestyle='dotted', color=f'C{f}')\n",
    "    ax2.plot(scattering_values[:i])\n",
    "    ax2.axhline(scattering_target, linestyle='dotted')\n",
    "    ax3.semilogy(losses[:i])\n",
    "    plot_etc(etc_ref, sampling_rate, max_time, dB=True, normalize=False, bottom=-100,\n",
    "             ax=ax4, linestyle='dotted', label='_nolabel')\n",
    "    ax4.set_prop_cycle(None) # reset plot colors\n",
    "    plot_etc(etc, sampling_rate, max_time, dB=True, normalize=False, bottom=-100,\n",
    "             ax=ax4, label=frequencies)\n",
    "\n",
    "    ax1.set_xlim(-iteration_count * 0.02, iteration_count * 1.02)\n",
    "    ax2.set_xlim(-iteration_count * 0.02, iteration_count * 1.02)\n",
    "    ax3.set_xlim(-iteration_count * 0.02, iteration_count * 1.02)\n",
    "    ax4.set_xlim(0.02, 0.08)\n",
    "\n",
    "    ax1.set_ylim(-0.1, 1.1)\n",
    "    ax2.set_ylim(-0.1, 1.1)\n",
    "    ax4.set_ylim(-100, -20)\n",
    "\n",
    "    ax1.set_xlabel('Iteration')\n",
    "    ax2.set_xlabel('Iteration')\n",
    "    ax3.set_xlabel('Iteration')\n",
    "    ax1.set_ylabel(rf'Absorption coefficient')\n",
    "    ax2.set_ylabel(rf'Scattering coefficient')\n",
    "    ax3.set_ylabel('Loss')\n",
    "    ax4.legend(title='Frequency in Hz')\n",
    "\n",
    "    fig.canvas.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mitsubadev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "07ec54878c3c410ca11e8b72444a00e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "0c35e343c7ef48baa2f16a89425e45c9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "100%"
      }
     },
     "121009d8ad1a400bb0faff5650af82b3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "148400d8a7d44374a39589fb0c0d7d46": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "100%"
      }
     },
     "1bf5946071df47e686b46976c829f4d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2262fd9b5af64b308ea9fd1d5b0b0494": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_0c35e343c7ef48baa2f16a89425e45c9",
       "max": 1,
       "style": "IPY_MODEL_64638caeb3de4839809e4dae0dc2b071",
       "value": 1
      }
     },
     "328d9c2dbd124dc19ae91ce0cb551403": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_493c51e117d545a799ea5a57b9bfb258",
        "IPY_MODEL_bc89b3250375423e82db58560d690de3"
       ],
       "layout": "IPY_MODEL_4352d146b8ac4b478de6fb1778cd5d41"
      }
     },
     "384ad0e5d7934e3b89951358a9d19186": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_cfb38214efa947568144d4522d548de6",
        "IPY_MODEL_c689f166d13242938ff57a24b0817d41"
       ],
       "layout": "IPY_MODEL_121009d8ad1a400bb0faff5650af82b3"
      }
     },
     "4352d146b8ac4b478de6fb1778cd5d41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "493c51e117d545a799ea5a57b9bfb258": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a3f5661d51064b2eb0e9ef5d1b0bb8aa",
       "style": "IPY_MODEL_b6610365565e4df1ab9f0dacfc0ee04a",
       "value": "Rendering (13.9s, ETA: 0ms)"
      }
     },
     "5ca4d20425df44658fb252c281f019fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "100%"
      }
     },
     "5ead71d75c28401eb61aaec2db79be71": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1bf5946071df47e686b46976c829f4d0",
       "style": "IPY_MODEL_f87d0eda3bba45a6b5101e92ec75ab51",
       "value": "Rendering (13.9s, ETA: 0ms)"
      }
     },
     "64638caeb3de4839809e4dae0dc2b071": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "64e097a514c04437bf30f0d12463d973": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_5ca4d20425df44658fb252c281f019fd",
       "max": 1,
       "style": "IPY_MODEL_07ec54878c3c410ca11e8b72444a00e8",
       "value": 1
      }
     },
     "6c57fb913d8b47c7ad6a2129294b7f4a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_c93f1917313f474c96018ef6f4db65b3",
        "IPY_MODEL_e1ec3d6d53ce43e386de054ab61583b5"
       ],
       "layout": "IPY_MODEL_cdad0127f4f6443a8643eec4140c2b50"
      }
     },
     "76ef1ebaa1c34d4ca27c8fda94d21eae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7995615f2c5648de87bc7080ce7043aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7b6bc4d7291243dcb4838f1745959151": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "895ccf032eb44c24a5e60315ff3eba16": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "100%"
      }
     },
     "9b86f1cff37c4fdc9e619cd95a70a256": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a3f5661d51064b2eb0e9ef5d1b0bb8aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a40669281c224b5f85fa4485491c3950": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_d7bb96993f3a4db4bb2aa71270257a1b",
        "IPY_MODEL_64e097a514c04437bf30f0d12463d973"
       ],
       "layout": "IPY_MODEL_76ef1ebaa1c34d4ca27c8fda94d21eae"
      }
     },
     "a6576f2dd3604fb79879caa19911b935": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b6610365565e4df1ab9f0dacfc0ee04a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b91e3ad4740c42798db154827fbe5477": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "bc89b3250375423e82db58560d690de3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_148400d8a7d44374a39589fb0c0d7d46",
       "max": 1,
       "style": "IPY_MODEL_e4fb04aa19fd44a49f0fdd5e9a4fa9fd",
       "value": 1
      }
     },
     "c689f166d13242938ff57a24b0817d41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_f1cc99986b0b46b58cae7fd82c5aad84",
       "max": 1,
       "style": "IPY_MODEL_e609a9ba6dff485bbde84e1fe599b2ba",
       "value": 1
      }
     },
     "c93f1917313f474c96018ef6f4db65b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ea57520c73bb4bf49de6ef0ab85b5fd5",
       "style": "IPY_MODEL_9b86f1cff37c4fdc9e619cd95a70a256",
       "value": "Rendering (34.1s, ETA: 0ms)"
      }
     },
     "cdad0127f4f6443a8643eec4140c2b50": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cfb38214efa947568144d4522d548de6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f92a16e114714e9e82f1e60a0980cb2d",
       "style": "IPY_MODEL_e11cbf07e2d240348cdc470bd4f234e7",
       "value": "Rendering (13.8s, ETA: 0ms)"
      }
     },
     "d7bb96993f3a4db4bb2aa71270257a1b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7995615f2c5648de87bc7080ce7043aa",
       "style": "IPY_MODEL_b91e3ad4740c42798db154827fbe5477",
       "value": "Rendering (14s, ETA: 0ms)"
      }
     },
     "d827ae3e316a4961b44fc24c2ef633a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_5ead71d75c28401eb61aaec2db79be71",
        "IPY_MODEL_2262fd9b5af64b308ea9fd1d5b0b0494"
       ],
       "layout": "IPY_MODEL_7b6bc4d7291243dcb4838f1745959151"
      }
     },
     "e11cbf07e2d240348cdc470bd4f234e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e1ec3d6d53ce43e386de054ab61583b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_895ccf032eb44c24a5e60315ff3eba16",
       "max": 1,
       "style": "IPY_MODEL_a6576f2dd3604fb79879caa19911b935",
       "value": 1
      }
     },
     "e4fb04aa19fd44a49f0fdd5e9a4fa9fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e609a9ba6dff485bbde84e1fe599b2ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ea57520c73bb4bf49de6ef0ab85b5fd5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f1cc99986b0b46b58cae7fd82c5aad84": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "100%"
      }
     },
     "f87d0eda3bba45a6b5101e92ec75ab51": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f92a16e114714e9e82f1e60a0980cb2d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
